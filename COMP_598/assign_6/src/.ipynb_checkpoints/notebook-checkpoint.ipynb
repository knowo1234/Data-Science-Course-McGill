{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json\n",
    "#import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CLIENT_ID = 'Fm91DhLSEMsxGwMA2m4RIQ'\n",
    "SECRET_KEY = 'XwKUdo-LCl63yS0Pp1y9tW0svMfU4A'\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID,SECRET_KEY)\n",
    "\n",
    "with open('../.env.example','r') as f:\n",
    "    pw = f.read()\n",
    "\n",
    "data = {\n",
    "    'grant_type': 'password',\n",
    "    'username': 'Comp598_hw6',\n",
    "    'password': pw\n",
    "}\n",
    "\n",
    "headers = {'User-Agent': 'MyAPI/0.0.1'}\n",
    "\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = res.json()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1262555207261-PL6jIgLUxWI8zCmh_JdYZXmPcCYcDA'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {**headers, **{'Authorization': f'bearer {TOKEN}'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'MyAPI/0.0.1',\n",
       " 'Authorization': 'bearer 1262555207261-PL6jIgLUxWI8zCmh_JdYZXmPcCYcDA'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define array of subreddit urls\n",
    "by_subsribers = ['funny','AskReddit','gaming','aww','pics','Music','science','worldnews','videos','todayilearned']\n",
    "by_posts = ['AskReddit','memes','politics','nfl','nba','wallstreetbets','teenagers','PublicFreakout','leagueoflegends','unpopularopinion']\n",
    "#url_new = 'https://www.reddit.com/r/{}/new/'.format(subreddit)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will do by subscribers\n",
    "\n",
    "scrape_url = 'https://oauth.reddit.com/r/funny/new/'\n",
    "reddit_titles = requests.get(scrape_url, \n",
    "                            headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example1.json','w+') as f:\n",
    "    jsonstr = json.dumps(reddit_titles.json()['data']['children'][1])\n",
    "    f.write(jsonstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('example1.json','w+')\n",
    "for subreddits in by_subsribers:\n",
    "    titles_array = []\n",
    "    scrape_url = 'https://oauth.reddit.com/r/{}/new?limit=100'.format(subreddits)\n",
    "    reddit_titles = requests.get(scrape_url, \n",
    "                                headers=headers)\n",
    "    \n",
    "    for i in range(0,100):\n",
    "            jsonstr = json.dumps(reddit_titles.json()['data']['children'][i])\n",
    "            f.write(jsonstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will do by subscribers\n",
    "titles_for_each_subreddit = {}\n",
    "for subreddits in by_subsribers:\n",
    "    titles_array = []\n",
    "    scrape_url = 'https://oauth.reddit.com/r/{}/new?limit=100'.format(subreddits)\n",
    "    reddit_titles = requests.get(scrape_url, \n",
    "                                headers=headers)\n",
    "    for i in range(0,100):\n",
    "        titles_array.append(reddit_titles.json()['data']['children'][i])#['data']['title'])\n",
    "    titles_for_each_subreddit.update({'{}'.format(subreddits):titles_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 't3',\n",
       " 'data': {'approved_at_utc': None,\n",
       "  'subreddit': 'todayilearned',\n",
       "  'selftext': '',\n",
       "  'author_fullname': 't2_3blfy75s',\n",
       "  'saved': False,\n",
       "  'mod_reason_title': None,\n",
       "  'gilded': 0,\n",
       "  'clicked': False,\n",
       "  'title': 'TIL Marinating Meats Before Cooking Them Makes Almost No Difference in the Flavor of the Finished Product',\n",
       "  'link_flair_richtext': [],\n",
       "  'subreddit_name_prefixed': 'r/todayilearned',\n",
       "  'hidden': False,\n",
       "  'pwls': 6,\n",
       "  'link_flair_css_class': None,\n",
       "  'downs': 0,\n",
       "  'thumbnail_height': 79,\n",
       "  'top_awarded_type': None,\n",
       "  'hide_score': True,\n",
       "  'name': 't3_qkpdax',\n",
       "  'quarantine': False,\n",
       "  'link_flair_text_color': 'dark',\n",
       "  'upvote_ratio': 0.24,\n",
       "  'author_flair_background_color': None,\n",
       "  'subreddit_type': 'public',\n",
       "  'ups': 0,\n",
       "  'total_awards_received': 0,\n",
       "  'media_embed': {},\n",
       "  'thumbnail_width': 140,\n",
       "  'author_flair_template_id': None,\n",
       "  'is_original_content': False,\n",
       "  'user_reports': [],\n",
       "  'secure_media': None,\n",
       "  'is_reddit_media_domain': False,\n",
       "  'is_meta': False,\n",
       "  'category': None,\n",
       "  'secure_media_embed': {},\n",
       "  'link_flair_text': None,\n",
       "  'can_mod_post': False,\n",
       "  'score': 0,\n",
       "  'approved_by': None,\n",
       "  'is_created_from_ads_ui': False,\n",
       "  'author_premium': False,\n",
       "  'thumbnail': 'https://b.thumbs.redditmedia.com/KnkwTOZxMNR510XaTFhj-v_jImUKmHlZ-EIKF97GrDw.jpg',\n",
       "  'edited': False,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'gildings': {},\n",
       "  'post_hint': 'link',\n",
       "  'content_categories': None,\n",
       "  'is_self': False,\n",
       "  'mod_note': None,\n",
       "  'created': 1635805162.0,\n",
       "  'link_flair_type': 'text',\n",
       "  'wls': 6,\n",
       "  'removed_by_category': None,\n",
       "  'banned_by': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'domain': 'splendidtable.org',\n",
       "  'allow_live_comments': True,\n",
       "  'selftext_html': None,\n",
       "  'likes': None,\n",
       "  'suggested_sort': None,\n",
       "  'banned_at_utc': None,\n",
       "  'url_overridden_by_dest': 'https://www.splendidtable.org/story/2017/06/02/food-myths-busted-by-americas-test-kitchen-marinating-basting-and-boiling',\n",
       "  'view_count': None,\n",
       "  'archived': False,\n",
       "  'no_follow': True,\n",
       "  'is_crosspostable': True,\n",
       "  'pinned': False,\n",
       "  'over_18': False,\n",
       "  'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/zPp5MQsZRrJDJdyhJrI26R3GDNESElUpX8UP0_jzdcE.jpg?auto=webp&amp;s=872f6686cd3dbf8f5e8fc1132e8715baa056ec6d',\n",
       "      'width': 1000,\n",
       "      'height': 571},\n",
       "     'resolutions': [{'url': 'https://external-preview.redd.it/zPp5MQsZRrJDJdyhJrI26R3GDNESElUpX8UP0_jzdcE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3755fbc83623d5194c208e5c385e4aeb2601c987',\n",
       "       'width': 108,\n",
       "       'height': 61},\n",
       "      {'url': 'https://external-preview.redd.it/zPp5MQsZRrJDJdyhJrI26R3GDNESElUpX8UP0_jzdcE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=535b308a8a4441432a17facb9e9945b28c8d55be',\n",
       "       'width': 216,\n",
       "       'height': 123},\n",
       "      {'url': 'https://external-preview.redd.it/zPp5MQsZRrJDJdyhJrI26R3GDNESElUpX8UP0_jzdcE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0a42a53ad477a6cd6d5ec795c28862ab69004e7',\n",
       "       'width': 320,\n",
       "       'height': 182},\n",
       "      {'url': 'https://external-preview.redd.it/zPp5MQsZRrJDJdyhJrI26R3GDNESElUpX8UP0_jzdcE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d8339d23b8c28e1f71823372b25b300dd9504b2',\n",
       "       'width': 640,\n",
       "       'height': 365},\n",
       "      {'url': 'https://external-preview.redd.it/zPp5MQsZRrJDJdyhJrI26R3GDNESElUpX8UP0_jzdcE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5c6f750c9cd5727f62266bb8a70ec673077de56e',\n",
       "       'width': 960,\n",
       "       'height': 548}],\n",
       "     'variants': {},\n",
       "     'id': 'iKE4FCTkgIkyWJ-c45nS3rSDvY3oAsE2gwMkpfy8exI'}],\n",
       "   'enabled': False},\n",
       "  'all_awardings': [],\n",
       "  'awarders': [],\n",
       "  'media_only': False,\n",
       "  'can_gild': True,\n",
       "  'spoiler': False,\n",
       "  'locked': False,\n",
       "  'author_flair_text': None,\n",
       "  'treatment_tags': [],\n",
       "  'visited': False,\n",
       "  'removed_by': None,\n",
       "  'num_reports': None,\n",
       "  'distinguished': None,\n",
       "  'subreddit_id': 't5_2qqjc',\n",
       "  'author_is_blocked': False,\n",
       "  'mod_reason_by': None,\n",
       "  'removal_reason': None,\n",
       "  'link_flair_background_color': '',\n",
       "  'id': 'qkpdax',\n",
       "  'is_robot_indexable': True,\n",
       "  'report_reasons': None,\n",
       "  'author': 'Emmyfishnappa',\n",
       "  'discussion_type': None,\n",
       "  'num_comments': 9,\n",
       "  'send_replies': True,\n",
       "  'whitelist_status': 'all_ads',\n",
       "  'contest_mode': False,\n",
       "  'mod_reports': [],\n",
       "  'author_patreon_flair': False,\n",
       "  'author_flair_text_color': None,\n",
       "  'permalink': '/r/todayilearned/comments/qkpdax/til_marinating_meats_before_cooking_them_makes/',\n",
       "  'parent_whitelist_status': 'all_ads',\n",
       "  'stickied': False,\n",
       "  'url': 'https://www.splendidtable.org/story/2017/06/02/food-myths-busted-by-americas-test-kitchen-marinating-basting-and-boiling',\n",
       "  'subreddit_subscribers': 26321303,\n",
       "  'created_utc': 1635805162.0,\n",
       "  'num_crossposts': 0,\n",
       "  'media': None,\n",
       "  'is_video': False}}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('example1.json','w+')\n",
    "for i in range(0,len(titles_array)):\n",
    "    jsonstr = json.dumps(titles_array[i])\n",
    "    f.write(jsonstr)\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'funny': 0,\n",
       " 'AskReddit': 0,\n",
       " 'gaming': 0,\n",
       " 'aww': 0,\n",
       " 'pics': 0,\n",
       " 'Music': 0,\n",
       " 'science': 0,\n",
       " 'worldnews': 0,\n",
       " 'videos': 0,\n",
       " 'todayilearned': 0}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_title_len = {}\n",
    "f = open('example1.json','r+')\n",
    "for line in f:\n",
    "    file = json.loads(line)\n",
    "    avg_title_len.update({file['data']['subreddit']:0})\n",
    "avg_title_len\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'funny': 0,\n",
       " 'AskReddit': 0,\n",
       " 'gaming': 0,\n",
       " 'aww': 0,\n",
       " 'pics': 0,\n",
       " 'Music': 0,\n",
       " 'science': 0,\n",
       " 'worldnews': 0,\n",
       " 'videos': 0,\n",
       " 'todayilearned': 0}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "avg_title_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'funny': 37.41,\n",
       " 'AskReddit': 74.04,\n",
       " 'gaming': 53.71,\n",
       " 'aww': 38.22,\n",
       " 'pics': 45.94,\n",
       " 'Music': 49.19,\n",
       " 'science': 136.09,\n",
       " 'worldnews': 85.26,\n",
       " 'videos': 51.53,\n",
       " 'todayilearned': 195.78}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dictionary that will hold the avg length of titles per subreddit\n",
    "\n",
    "f = open('example1.json','r+')\n",
    "denominator = 0\n",
    "for line in f:\n",
    "    denominator = denominator +1\n",
    "    file = json.loads(line)\n",
    "    avg_title_len[file['data']['subreddit']] = len(file['data']['title']) + avg_title_len[file['data']['subreddit']]\n",
    "f.close()\n",
    "denominator = denominator/len(avg_title_len.keys())\n",
    "for subreddit in avg_title_len.keys():\n",
    "    avg_title_len[subreddit] = round(avg_title_len[subreddit]/denominator,2)\n",
    "print(avg_title_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
